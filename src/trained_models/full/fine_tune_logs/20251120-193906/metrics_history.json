[
  {
    "epoch": 0,
    "step": 0,
    "train_loss": 0.0,
    "val_loss": 564.4653930664062,
    "train_mae": 0.0,
    "val_mae": 564.96533203125,
    "train_rmse": 0.0,
    "val_rmse": 648.2249755859375
  },
  {
    "epoch": 0,
    "step": 88,
    "train_loss": 332.5434875488281,
    "val_loss": 306.4565124511719,
    "train_mae": 333.0434875488281,
    "val_mae": 306.9558410644531,
    "train_rmse": 0.0,
    "val_rmse": 376.7808532714844
  },
  {
    "epoch": 1,
    "step": 176,
    "train_loss": 315.7466735839844,
    "val_loss": 287.56024169921875,
    "train_mae": 316.2466735839844,
    "val_mae": 288.0588073730469,
    "train_rmse": 396.9609680175781,
    "val_rmse": 352.9759521484375
  },
  {
    "epoch": 2,
    "step": 264,
    "train_loss": 255.6512908935547,
    "val_loss": 269.0574645996094,
    "train_mae": 256.1512756347656,
    "val_mae": 269.5567626953125,
    "train_rmse": 368.15899658203125,
    "val_rmse": 335.67529296875
  },
  {
    "epoch": 3,
    "step": 352,
    "train_loss": 245.10040283203125,
    "val_loss": 249.9597625732422,
    "train_mae": 245.60040283203125,
    "val_mae": 250.4593505859375,
    "train_rmse": 342.8417053222656,
    "val_rmse": 308.6044921875
  },
  {
    "epoch": 4,
    "step": 440,
    "train_loss": 240.0537567138672,
    "val_loss": 240.71202087402344,
    "train_mae": 240.5537567138672,
    "val_mae": 241.211181640625,
    "train_rmse": 323.71588134765625,
    "val_rmse": 295.9555969238281
  },
  {
    "epoch": 5,
    "step": 528,
    "train_loss": 244.21466064453125,
    "val_loss": 226.06869506835938,
    "train_mae": 244.71466064453125,
    "val_mae": 226.56787109375,
    "train_rmse": 306.1979675292969,
    "val_rmse": 278.4313659667969
  },
  {
    "epoch": 6,
    "step": 616,
    "train_loss": 194.85008239746094,
    "val_loss": 216.01268005371094,
    "train_mae": 195.35008239746094,
    "val_mae": 216.5118408203125,
    "train_rmse": 289.87744140625,
    "val_rmse": 266.9397888183594
  },
  {
    "epoch": 7,
    "step": 704,
    "train_loss": 182.9402313232422,
    "val_loss": 204.7338409423828,
    "train_mae": 183.4336395263672,
    "val_mae": 205.23272705078125,
    "train_rmse": 274.4784851074219,
    "val_rmse": 253.57875061035156
  },
  {
    "epoch": 8,
    "step": 792,
    "train_loss": 207.71926879882812,
    "val_loss": 197.36383056640625,
    "train_mae": 208.21522521972656,
    "val_mae": 197.86253356933594,
    "train_rmse": 261.3015441894531,
    "val_rmse": 246.8129425048828
  },
  {
    "epoch": 9,
    "step": 880,
    "train_loss": 202.83555603027344,
    "val_loss": 191.83267211914062,
    "train_mae": 203.33555603027344,
    "val_mae": 192.3326416015625,
    "train_rmse": 252.6791534423828,
    "val_rmse": 240.04420471191406
  },
  {
    "epoch": 10,
    "step": 968,
    "train_loss": 197.0467071533203,
    "val_loss": 189.10191345214844,
    "train_mae": 197.5467071533203,
    "val_mae": 189.60133361816406,
    "train_rmse": 244.7981414794922,
    "val_rmse": 237.41993713378906
  },
  {
    "epoch": 11,
    "step": 1056,
    "train_loss": 191.0967254638672,
    "val_loss": 180.8207244873047,
    "train_mae": 191.5967254638672,
    "val_mae": 181.32064819335938,
    "train_rmse": 234.0450439453125,
    "val_rmse": 228.7986602783203
  },
  {
    "epoch": 12,
    "step": 1144,
    "train_loss": 170.66152954101562,
    "val_loss": 176.05970764160156,
    "train_mae": 171.16152954101562,
    "val_mae": 176.55935668945312,
    "train_rmse": 230.41929626464844,
    "val_rmse": 224.96148681640625
  },
  {
    "epoch": 13,
    "step": 1232,
    "train_loss": 161.04942321777344,
    "val_loss": 178.7069549560547,
    "train_mae": 161.54942321777344,
    "val_mae": 179.20654296875,
    "train_rmse": 225.70346069335938,
    "val_rmse": 225.29754638671875
  },
  {
    "epoch": 14,
    "step": 1320,
    "train_loss": 198.9058380126953,
    "val_loss": 175.21102905273438,
    "train_mae": 199.4058380126953,
    "val_mae": 175.71099853515625,
    "train_rmse": 222.09295654296875,
    "val_rmse": 222.5880889892578
  },
  {
    "epoch": 15,
    "step": 1408,
    "train_loss": 152.37339782714844,
    "val_loss": 174.32614135742188,
    "train_mae": 152.8686065673828,
    "val_mae": 174.82521057128906,
    "train_rmse": 218.2366943359375,
    "val_rmse": 222.3367156982422
  },
  {
    "epoch": 16,
    "step": 1496,
    "train_loss": 192.51234436035156,
    "val_loss": 181.7223358154297,
    "train_mae": 193.01234436035156,
    "val_mae": 182.2220001220703,
    "train_rmse": 214.28225708007812,
    "val_rmse": 228.11354064941406
  },
  {
    "epoch": 17,
    "step": 1584,
    "train_loss": 182.0618133544922,
    "val_loss": 170.14263916015625,
    "train_mae": 182.5618133544922,
    "val_mae": 170.64170837402344,
    "train_rmse": 212.56089782714844,
    "val_rmse": 216.70947265625
  },
  {
    "epoch": 18,
    "step": 1672,
    "train_loss": 169.6585235595703,
    "val_loss": 166.36282348632812,
    "train_mae": 170.1585235595703,
    "val_mae": 166.86256408691406,
    "train_rmse": 210.86288452148438,
    "val_rmse": 211.82676696777344
  },
  {
    "epoch": 19,
    "step": 1760,
    "train_loss": 156.6959686279297,
    "val_loss": 160.48739624023438,
    "train_mae": 157.1959686279297,
    "val_mae": 160.98683166503906,
    "train_rmse": 208.39662170410156,
    "val_rmse": 205.13760375976562
  },
  {
    "epoch": 20,
    "step": 1848,
    "train_loss": 153.2894744873047,
    "val_loss": 161.05926513671875,
    "train_mae": 153.78944396972656,
    "val_mae": 161.55845642089844,
    "train_rmse": 205.9261932373047,
    "val_rmse": 205.90159606933594
  },
  {
    "epoch": 21,
    "step": 1936,
    "train_loss": 166.0631866455078,
    "val_loss": 160.0606231689453,
    "train_mae": 166.5631866455078,
    "val_mae": 160.5601806640625,
    "train_rmse": 204.55517578125,
    "val_rmse": 206.97300720214844
  },
  {
    "epoch": 22,
    "step": 2024,
    "train_loss": 140.2069091796875,
    "val_loss": 158.82569885253906,
    "train_mae": 140.7069091796875,
    "val_mae": 159.32469177246094,
    "train_rmse": 204.50595092773438,
    "val_rmse": 204.25999450683594
  },
  {
    "epoch": 23,
    "step": 2112,
    "train_loss": 132.77587890625,
    "val_loss": 158.0254669189453,
    "train_mae": 133.27587890625,
    "val_mae": 158.525390625,
    "train_rmse": 201.15353393554688,
    "val_rmse": 201.37892150878906
  },
  {
    "epoch": 24,
    "step": 2200,
    "train_loss": 165.6245574951172,
    "val_loss": 157.15444946289062,
    "train_mae": 166.1245574951172,
    "val_mae": 157.6539306640625,
    "train_rmse": 199.98590087890625,
    "val_rmse": 202.3068389892578
  }
]